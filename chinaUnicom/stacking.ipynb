{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path = \"C:/Data/chinaUnicom/\"\n",
    "train_data = pd.read_csv(path + \"train/train_.csv\")\n",
    "test_data = pd.read_csv(path + \"test/test_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征处理\n",
    "def increaseFeatures(train):\n",
    "    # 费用\n",
    "    train['avg_total_fee']=(train['1_total_fee']+train['2_total_fee']+train['3_total_fee']+train['3_total_fee']).astype(float)/4.0\n",
    "    train['sum_total_fee'] = (train['1_total_fee']+train['2_total_fee']+train['3_total_fee']+train['3_total_fee']).astype(float)\n",
    "    train['pay_num_per'] = train['pay_num'].astype(float)/train['pay_times']\n",
    "    train['contract_timex_feex_over_bill'] = (train['avg_total_fee']*train['contract_time']*train['many_over_bill']).astype(float)\n",
    "    train['contract_online_time_rate'] = (train['contract_time']/train['online_time']).astype(float)\n",
    "    # 流量\n",
    "    train['sum_traffic_month'] = train['month_traffic'] + train['local_trafffic_month']+1\n",
    "    train['out_local_traffic_rate'] = train['month_traffic'].astype(float)/train['sum_traffic_month']\n",
    "    train['local_sum_traffic_rate'] = train['local_trafffic_month'].astype(float)/train['sum_traffic_month']\n",
    "    train['last_month_sum_traffic_rate'] = train['last_month_traffic'].astype(float)/train['sum_traffic_month']\n",
    "    # 通话时间\n",
    "    train['sum_caller_receive_time'] = train['local_caller_time']+train['service1_caller_time']+train['service2_caller_time']+1\n",
    "    train['sum_caller_time'] = train['local_caller_time']+train['service1_caller_time']\n",
    "    train['caller_receive_time_rate'] = train['sum_caller_time'].astype(float)/(train['sum_caller_receive_time'])\n",
    "    # 流量+通话时间+费用\n",
    "    train['month_traffic_total_fee_rate'] = train['sum_traffic_month'].astype(float)/train['sum_caller_receive_time']\n",
    "    train['month_traffic_caller_rate'] = train['sum_traffic_month'].astype(float)/(train['1_total_fee']+1)\n",
    "    train['caller_time_total_fee_rate'] = train['sum_caller_receive_time'].astype(float)/(train['1_total_fee']+1)\n",
    "    #省内、本地流量通话\n",
    "    train['local_trafficx_local_caller'] = train['local_trafffic_month']*train['local_caller_time'].astype(float)\n",
    "    train['month_trafficx_service1_call'] = train['month_traffic']*train['service1_caller_time'].astype(float)\n",
    "    \n",
    "    return train\n",
    "\n",
    "train_data = increaseFeatures(train_data)\n",
    "test_data = increaseFeatures(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label 处理函数 转为0--14序列或者One_Hot序列\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def service2label(current_service,One_hot = False):\n",
    "    le = LabelEncoder()\n",
    "    tmp = sorted(current_service.unique())\n",
    "    le.fit(tmp)\n",
    "    label = le.transform(current_service)\n",
    "    ohe_tmp = le.transform(tmp)\n",
    "    if(One_hot==True):\n",
    "        ohe = OneHotEncoder()\n",
    "        ohe.fit(ohe_tmp.reshape(-1,1))\n",
    "        label = ohe.transform(label.reshape(-1,1)).toarray()\n",
    "    return label\n",
    "# label 处理\n",
    "current_service_label = train_data['current_service']\n",
    "label = service2label(current_service_label,One_hot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_feature = train_data.columns\n",
    "train_data.dropna(axis=0,how='any')#删除任何带有NaN值得行\n",
    "train_data.fillna(0)\n",
    "train = train_data.drop(['current_service','user_id','sum_total_fee','net_service','complaint_level','former_complaint_num','former_complaint_fee'],axis=1)\n",
    "original_feature_new = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_validate,y_train,y_validate = train_test_split(train[original_feature_new],label,test_size=0.3,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    " \n",
    "clf1 = KNeighborsClassifier(n_neighbors=5)\n",
    "clf2 = RandomForestClassifier(n_estimators=500,random_state=200,criterion='gini')\n",
    "clf3 = xgb.XGBClassifier(max_depth=30, min_child_weight=1, n_estimators=300,n_jobs=-1 ,verbose=1,learning_rate=0.025)\n",
    "clf4 = GradientBoostingClassifier(n_estimators=500,learning_rate=0.1,random_state=10,subsample=0.8)\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3,clf4],\n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=lr)\n",
    " \n",
    "print('4-fold cross validation:\\n')\n",
    " \n",
    "for clf, label in zip([clf1, clf2, clf3,clf4, sclf],['KNN', 'Random Forest','XGB','GDBT','StackingClassifier']):\n",
    "    scores = model_selection.cross_val_score(clf, X_train, y_train,cv=4, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\"  % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeldic = {}\n",
    "tmp = sorted(train_data['current_service'].unique())\n",
    "for i in range(15):\n",
    "    labeldic[i] = tmp[i]\n",
    "for j in range(len(pred)):\n",
    "    pred[j]=labeldic[pred[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(path+\"stacking_submission.csv\",\"w\",newline='',encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"user_id\",\"current_service\"])\n",
    "    for i in range(len(test_data)):\n",
    "        writer.writerow([test_data['user_id'][i],pred[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
